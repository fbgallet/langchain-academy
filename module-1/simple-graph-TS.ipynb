{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d5f3703",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-1/simple-graph.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58238187-lesson-2-simple-graph)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50fa7f8a-8764-4bb9-9968-48b681a0e4f1",
   "metadata": {},
   "source": [
    "# The Simplest Graph\n",
    "\n",
    "Let's build a simple graph with 3 nodes and one conditional edge. \n",
    "\n",
    "![Screenshot 2024-08-20 at 3.11.22 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dba5f465f6e9a2482ad935_simple-graph1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff151ef1-fa30-482a-94da-8f49964afbc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "Expression expected at file:///repl.tsx:1:2\n\n  %%capture --no-stderr\n   ~",
     "evalue": "Expression expected at file:///repl.tsx:1:2\n\n  %%capture --no-stderr\n   ~",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5999f8d0-989f-4638-8ade-5c257cbadfe8",
   "metadata": {},
   "source": [
    "## State\n",
    "\n",
    "First, define the [State](https://langchain-ai.github.io/langgraph/concepts/low_level/#state) of the graph. \n",
    "\n",
    "The State schema serves as the input schema for all Nodes and Edges in the graph.\n",
    "\n",
    "Let's use the `TypedDict` class from python's `typing` module as our schema, which provides type hints for the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a90709b-ddfa-4671-8acc-c59969a29991",
   "metadata": {},
   "outputs": [],
   "source": [
    "//from typing_extensions import TypedDict\n",
    "\n",
    "//class State(TypedDict):\n",
    "  //  graph_state: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888509e1-cbde-4c03-99a0-2560dd2e262d",
   "metadata": {},
   "source": [
    "## Nodes\n",
    "\n",
    "[Nodes](https://langchain-ai.github.io/langgraph/concepts/low_level/#nodes) are just python functions.\n",
    "\n",
    "The first positional argument is the state, as defined above.\n",
    "\n",
    "Because the state is a `TypedDict` with schema as defined above, each node can access the key, `graph_state`, with `state['graph_state']`.\n",
    "\n",
    "Each node returns a new value of the state key `graph_state`.\n",
    "  \n",
    "By default, the new value returned by each node [will override](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) the prior state value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8aabcb7-494c-4d35-be08-f81c76d75a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface GraphState {\n",
    "    graph_state: string;\n",
    "  }\n",
    "  \n",
    "\n",
    "\n",
    "  const node1 = (state: GraphState): GraphState => {\n",
    "    console.log(\"---Node 1---\");\n",
    "    return { graph_state: state.graph_state + \" I am\" };\n",
    "  }\n",
    "  \n",
    "  const node2 = (state: GraphState): GraphState => {\n",
    "    console.log(\"---Node 2---\");\n",
    "    return { graph_state: state.graph_state + \" happy!\" }; \n",
    "  }\n",
    "  \n",
    "  const node3 = (state: GraphState): GraphState => {\n",
    "    console.log(\"---Node 3---\");\n",
    "    return { graph_state: state.graph_state + \" sad!\" };\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad056608-8c8f-4999-bb53-10583efa4ed8",
   "metadata": {},
   "source": [
    "## Edges\n",
    "\n",
    "[Edges](https://langchain-ai.github.io/langgraph/concepts/low_level/#edges) connect the nodes.\n",
    "\n",
    "Normal Edges are used if you want to *always* go from, for example, `node_1` to `node_2`.\n",
    "\n",
    "[Conditional Edges](https://langchain-ai.github.io/langgraph/reference/graphs/?h=conditional+edge#langgraph.graph.StateGraph.add_conditional_edges) are used want to *optionally* route between nodes.\n",
    " \n",
    "Conditional edges are implemented as functions that return the next node to visit based upon some logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e53543a-902a-4d41-ad3d-25eee260e819",
   "metadata": {},
   "outputs": [],
   "source": [
    "type NextNode = \"node_2\" | \"node_3\";\n",
    "\n",
    "const decideMood = (state: GraphState): NextNode => {\n",
    "  // Often, we will use state to decide on the next node to visit\n",
    "  const userInput = state.graph_state;\n",
    "\n",
    "  // Here, let's just do a 50 / 50 split between nodes 2, 3\n",
    "  if (Math.random() < 0.5) {\n",
    "    // 50% of the time, we return Node 2\n",
    "    return \"node_2\";\n",
    "  }\n",
    "\n",
    "  // 50% of the time, we return Node 3\n",
    "  return \"node_3\"; \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9282ea7a-5ed2-4641-bed8-c3472d54c951",
   "metadata": {},
   "source": [
    "## Graph Construction\n",
    "\n",
    "Now, we build the graph from our [components](\n",
    "https://langchain-ai.github.io/langgraph/concepts/low_level/) defined above.\n",
    "\n",
    "The [StateGraph class](https://langchain-ai.github.io/langgraph/concepts/low_level/#stategraph) is the graph class that we can use.\n",
    " \n",
    "First, we initialize a StateGraph with the `State` class we defined above.\n",
    " \n",
    "Then, we add our nodes and edges.\n",
    "\n",
    "We use the [`START` Node, a special node](https://langchain-ai.github.io/langgraph/concepts/low_level/#start-node) that sends user input to the graph, to indicate where to start our graph.\n",
    " \n",
    "The [`END` Node](https://langchain-ai.github.io/langgraph/concepts/low_level/#end-node) is a special node that represents a terminal node. \n",
    "\n",
    "Finally, we [compile our graph](https://langchain-ai.github.io/langgraph/concepts/low_level/#compiling-your-graph) to perform a few basic checks on the graph structure. \n",
    "\n",
    "We can visualize the graph as a [Mermaid diagram](https://github.com/mermaid-js/mermaid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7deb0359-55c1-4545-b52e-8252994befbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateGraph {\n",
       "  nodes: {\n",
       "    node_1: {\n",
       "      runnable: RunnableCallable {\n",
       "        lc_serializable: \u001b[33mfalse\u001b[39m,\n",
       "        lc_kwargs: {},\n",
       "        lc_runnable: \u001b[33mtrue\u001b[39m,\n",
       "        name: \u001b[32m\"node_1\"\u001b[39m,\n",
       "        lc_namespace: [ \u001b[32m\"langgraph\"\u001b[39m ],\n",
       "        func: \u001b[36m[Function: node1]\u001b[39m,\n",
       "        tags: \u001b[90mundefined\u001b[39m,\n",
       "        config: \u001b[90mundefined\u001b[39m,\n",
       "        trace: \u001b[33mfalse\u001b[39m,\n",
       "        recurse: \u001b[33mtrue\u001b[39m\n",
       "      },\n",
       "      retryPolicy: \u001b[90mundefined\u001b[39m,\n",
       "      metadata: \u001b[90mundefined\u001b[39m,\n",
       "      input: {\n",
       "        graph_state: [Function: Annotation] { Root: \u001b[36m[Function (anonymous)]\u001b[39m }\n",
       "      },\n",
       "      subgraphs: \u001b[90mundefined\u001b[39m\n",
       "    },\n",
       "    node_2: {\n",
       "      runnable: RunnableCallable {\n",
       "        lc_serializable: \u001b[33mfalse\u001b[39m,\n",
       "        lc_kwargs: {},\n",
       "        lc_runnable: \u001b[33mtrue\u001b[39m,\n",
       "        name: \u001b[32m\"node_2\"\u001b[39m,\n",
       "        lc_namespace: [ \u001b[32m\"langgraph\"\u001b[39m ],\n",
       "        func: \u001b[36m[Function: node2]\u001b[39m,\n",
       "        tags: \u001b[90mundefined\u001b[39m,\n",
       "        config: \u001b[90mundefined\u001b[39m,\n",
       "        trace: \u001b[33mfalse\u001b[39m,\n",
       "        recurse: \u001b[33mtrue\u001b[39m\n",
       "      },\n",
       "      retryPolicy: \u001b[90mundefined\u001b[39m,\n",
       "      metadata: \u001b[90mundefined\u001b[39m,\n",
       "      input: {\n",
       "        graph_state: [Function: Annotation] { Root: \u001b[36m[Function (anonymous)]\u001b[39m }\n",
       "      },\n",
       "      subgraphs: \u001b[90mundefined\u001b[39m\n",
       "    },\n",
       "    node_3: {\n",
       "      runnable: RunnableCallable {\n",
       "        lc_serializable: \u001b[33mfalse\u001b[39m,\n",
       "        lc_kwargs: {},\n",
       "        lc_runnable: \u001b[33mtrue\u001b[39m,\n",
       "        name: \u001b[32m\"node_3\"\u001b[39m,\n",
       "        lc_namespace: [ \u001b[32m\"langgraph\"\u001b[39m ],\n",
       "        func: \u001b[36m[Function: node3]\u001b[39m,\n",
       "        tags: \u001b[90mundefined\u001b[39m,\n",
       "        config: \u001b[90mundefined\u001b[39m,\n",
       "        trace: \u001b[33mfalse\u001b[39m,\n",
       "        recurse: \u001b[33mtrue\u001b[39m\n",
       "      },\n",
       "      retryPolicy: \u001b[90mundefined\u001b[39m,\n",
       "      metadata: \u001b[90mundefined\u001b[39m,\n",
       "      input: {\n",
       "        graph_state: [Function: Annotation] { Root: \u001b[36m[Function (anonymous)]\u001b[39m }\n",
       "      },\n",
       "      subgraphs: \u001b[90mundefined\u001b[39m\n",
       "    }\n",
       "  },\n",
       "  edges: Set(3) {\n",
       "    [ \u001b[32m\"__start__\"\u001b[39m, \u001b[32m\"node_1\"\u001b[39m ],\n",
       "    [ \u001b[32m\"node_2\"\u001b[39m, \u001b[32m\"__end__\"\u001b[39m ],\n",
       "    [ \u001b[32m\"node_3\"\u001b[39m, \u001b[32m\"__end__\"\u001b[39m ]\n",
       "  },\n",
       "  branches: {\n",
       "    node_1: {\n",
       "      decideMood: Branch { condition: \u001b[36m[Function: decideMood]\u001b[39m, ends: \u001b[90mundefined\u001b[39m }\n",
       "    }\n",
       "  },\n",
       "  entryPoint: \u001b[90mundefined\u001b[39m,\n",
       "  compiled: \u001b[33mtrue\u001b[39m,\n",
       "  channels: {\n",
       "    graph_state: LastValue {\n",
       "      ValueType: \u001b[90mundefined\u001b[39m,\n",
       "      UpdateType: \u001b[90mundefined\u001b[39m,\n",
       "      lg_is_channel: \u001b[33mtrue\u001b[39m,\n",
       "      lc_graph_name: \u001b[32m\"LastValue\"\u001b[39m,\n",
       "      value: \u001b[90mundefined\u001b[39m\n",
       "    }\n",
       "  },\n",
       "  waitingEdges: Set(0) {},\n",
       "  _schemaDefinition: {\n",
       "    graph_state: [Function: Annotation] { Root: \u001b[36m[Function (anonymous)]\u001b[39m }\n",
       "  },\n",
       "  _inputDefinition: {\n",
       "    graph_state: [Function: Annotation] { Root: \u001b[36m[Function (anonymous)]\u001b[39m }\n",
       "  },\n",
       "  _outputDefinition: {\n",
       "    graph_state: [Function: Annotation] { Root: \u001b[36m[Function (anonymous)]\u001b[39m }\n",
       "  },\n",
       "  _schemaDefinitions: Map(1) {\n",
       "    {\n",
       "      graph_state: [Function: Annotation] { Root: \u001b[36m[Function (anonymous)]\u001b[39m }\n",
       "    } => {\n",
       "      graph_state: [Function: Annotation] { Root: \u001b[36m[Function (anonymous)]\u001b[39m }\n",
       "    }\n",
       "  },\n",
       "  _configSchema: \u001b[90mundefined\u001b[39m\n",
       "}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { StateGraph,Annotation, START, END } from '@langchain/langgraph';\n",
    "\n",
    "const StateAnnotation = Annotation.Root({\n",
    "    graph_state: Annotation<string>,\n",
    "  });\n",
    "// Build graph\n",
    "const builder = new StateGraph(StateAnnotation);\n",
    "builder.addNode(\"node_1\", node1)\n",
    ".addNode(\"node_2\", node2)\n",
    ".addNode(\"node_3\", node3)\n",
    "\n",
    "// Logic\n",
    ".addEdge(START, \"node_1\")\n",
    ".addConditionalEdges(\"node_1\", decideMood)\n",
    ".addEdge(\"node_2\", END)\n",
    ".addEdge(\"node_3\", END);\n",
    "\n",
    "// Compile\n",
    "export const graph = builder.compile();\n",
    "\n",
    "// View - Note: Implementation may vary based on visualization library\n",
    "// This is a pseudo-code equivalent\n",
    "// graph.view(); // Or similar visualization method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00617c74-2647-44ea-8a2e-310dd96c0d26",
   "metadata": {},
   "source": [
    "## Graph Invocation\n",
    "\n",
    "The compiled graph implements the [runnable](https://python.langchain.com/v0.1/docs/expression_language/interface/) protocol.\n",
    "\n",
    "This provides a standard way to execute LangChain components. \n",
    " \n",
    "`invoke` is one of the standard methods in this interface.\n",
    "\n",
    "The input is a dictionary `{\"graph_state\": \"Hi, this is lance.\"}`, which sets the initial value for our graph state dict.\n",
    "\n",
    "When `invoke` is called, the graph starts execution from the `START` node.\n",
    "\n",
    "It progresses through the defined nodes (`node_1`, `node_2`, `node_3`) in order.\n",
    "\n",
    "The conditional edge will traverse from node `1` to node `2` or `3` using a 50/50 decision rule. \n",
    "\n",
    "Each node function receives the current state and returns a new value, which overrides the graph state.\n",
    "\n",
    "The execution continues until it reaches the `END` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e895f17a-e835-4e8a-8e1b-63fe6d27cc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Node 1---\n",
      "---Node 2---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Promise { { graph_state: \u001b[32m\"Hi, this is Lance. I am happy!\"\u001b[39m } }"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"graph_state\" : \"Hi, this is Lance.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082399c3-18bd-4b67-97c1-2005f268abc5",
   "metadata": {},
   "source": [
    "`invoke` runs the entire graph synchronously.\n",
    "\n",
    "This waits for each step to complete before moving to the next.\n",
    "\n",
    "It returns the final state of the graph after all nodes have executed.\n",
    "\n",
    "In this case, it returns the state after `node_3` has completed: \n",
    "\n",
    "```\n",
    "{'graph_state': 'Hi, this is Lance. I am sad!'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db16ab8d-b817-4f3a-befc-a02b579c4fca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
