{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cbf2458",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-1/chain.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58238466-lesson-4-chain)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee55d3da-c53a-4c76-b46f-8e0d602e072e",
   "metadata": {},
   "source": [
    "# Chain\n",
    "\n",
    "## Review\n",
    "\n",
    "We built a simple graph with nodes, normal edges, and conditional edges.\n",
    "\n",
    "## Goals\n",
    "\n",
    "Now, let's build up to a simple chain that combines 4 [concepts](https://python.langchain.com/v0.2/docs/concepts/):\n",
    "\n",
    "* Using [chat messages](https://python.langchain.com/v0.2/docs/concepts/#messages) as our graph state\n",
    "* Using [chat models](https://python.langchain.com/v0.2/docs/concepts/#chat-models) in graph nodes\n",
    "* [Binding tools](https://python.langchain.com/v0.2/docs/concepts/#tools) to our chat model\n",
    "* [Executing tool calls](https://python.langchain.com/v0.2/docs/concepts/#functiontool-calling) in graph nodes \n",
    "\n",
    "![Screenshot 2024-08-21 at 9.24.03 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dd607b08df5e1101_chain1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55e2e80-a718-4aaf-99b9-371157b34a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ac2d0-c7b0-4a20-86e5-4b6ed15ec20e",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "Chat models can use [`messages`](https://python.langchain.com/v0.2/docs/concepts/#messages), which capture different roles within a conversation. \n",
    "\n",
    "LangChain supports various message types, including `HumanMessage`, `AIMessage`, `SystemMessage`, and `ToolMessage`. \n",
    "\n",
    "These represent a message from the user, from chat model, for the chat model to instruct behavior, and from a tool call. \n",
    "\n",
    "Let's create a list of messages. \n",
    "\n",
    "Each message can be supplied with a few things:\n",
    "\n",
    "* `content` - content of the message\n",
    "* `name` - optionally, a message author \n",
    "* `response_metadata` - optionally, a dict of metadata (e.g., often populated by model provider for `AIMessages`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "866b5321-a238-4a9e-af9e-f11a131b5f11",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Identifier 'messages' has already been declared",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "SyntaxError: Identifier 'messages' has already been declared"
     ]
    }
   ],
   "source": [
    "import {AIMessage, HumanMessage} from \"@langchain/core/messages\";\n",
    "\n",
    "let messages = [new AIMessage({content:\"So you said you were researching ocean mammals?\", name:\"Model\"})]\n",
    "messages.push(new HumanMessage({content:\"Yes, that's right.\",name:\"Lance\"}))\n",
    "messages.push(new AIMessage({content:\"Great, what would you like to learn about.\", name:\"Model\"}))\n",
    "messages.push(new HumanMessage({content:\"I want to learn about the best place to see Orcas in the US.\", name:\"Lance\"}))\n",
    "\n",
    "messages.forEach(message => {\n",
    "    console.log(message);\n",
    "  });"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca48df0-b639-4ff1-a777-ffe2185d991e",
   "metadata": {},
   "source": [
    "## Chat Models\n",
    "\n",
    "[Chat models](https://python.langchain.com/v0.2/docs/concepts/#chat-models) can use a sequence of message as input and support message types, as discussed above.\n",
    "\n",
    "There are [many](https://python.langchain.com/v0.2/docs/concepts/#chat-models) to choose from! Let's work with OpenAI. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceae53d4-14f5-4bf3-a953-cc465240f5b5",
   "metadata": {},
   "source": [
    "We can load a chat model and invoke it with out list of messages.\n",
    "\n",
    "We can see that the result is an `AIMessage` with specific `response_metadata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95b99ad4-5753-49d3-a916-a9e949722c01",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "promptValue.toChatMessages is not a function",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "TypeError: promptValue.toChatMessages is not a function",
      "    at file:///Users/fabrice/Documents/Dev Local/Tutoriels/langchain-academy/node_modules/@langchain/core/dist/language_models/chat_models.js:402:78",
      "    at Array.map (<anonymous>)",
      "    at ChatOpenAI.generatePrompt (file:///Users/fabrice/Documents/Dev Local/Tutoriels/langchain-academy/node_modules/@langchain/core/dist/language_models/chat_models.js:402:45)",
      "    at ChatOpenAI.invoke (file:///Users/fabrice/Documents/Dev Local/Tutoriels/langchain-academy/node_modules/@langchain/core/dist/language_models/chat_models.js:56:35)",
      "    at <anonymous>:5:26",
      "    at eventLoopTick (ext:core/01_core.js:175:7)"
     ]
    }
   ],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "const llm = new ChatOpenAI({model:\"gpt-4o\"});\n",
    "const result = await llm.invoke(messages);\n",
    "console.log('result :>> ', result.content);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3a29654-6b8e-4eda-9cec-22fabb9b8620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  tokenUsage: { promptTokens: 67, completionTokens: 299, totalTokens: 366 },\n",
      "  finish_reason: \"stop\",\n",
      "  usage: {\n",
      "    prompt_tokens: 67,\n",
      "    completion_tokens: 299,\n",
      "    total_tokens: 366,\n",
      "    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },\n",
      "    completion_tokens_details: {\n",
      "      reasoning_tokens: 0,\n",
      "      audio_tokens: 0,\n",
      "      accepted_prediction_tokens: 0,\n",
      "      rejected_prediction_tokens: 0\n",
      "    }\n",
      "  },\n",
      "  system_fingerprint: \"fp_831e067d82\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "console.log(result.response_metadata)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4718bd5c-5314-4405-a164-f1fe912ae306",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "Tools are useful whenever you want a model to interact with external systems.\n",
    "\n",
    "External systems (e.g., APIs) often require a particular input schema or payload, rather than natural language. \n",
    "\n",
    "When we bind an API, for example, as a tool we given the model awareness of the required input schema.\n",
    "\n",
    "The model will choose to call a tool based upon the natural language input from the user. \n",
    "\n",
    "And, it will return an output that adheres to the tool's schema. \n",
    "\n",
    "[Many LLM providers support tool calling](https://python.langchain.com/v0.1/docs/integrations/chat/) and [tool calling interface](https://blog.langchain.dev/improving-core-tool-interfaces-and-docs-in-langchain/) in LangChain is simple. \n",
    " \n",
    "You can simply pass any Python `function` into `ChatModel.bind_tools(function)`.\n",
    "\n",
    "![Screenshot 2024-08-19 at 7.46.28 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dc1c17a7a57f9960_chain2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a942b1",
   "metadata": {},
   "source": [
    "Let's showcase a simple example of tool calling!\n",
    " \n",
    "The `multiply` function is our tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "928faf56-1a1a-4c5f-b97d-bd64d8e166d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    " * Multiply a and b.\n",
    " * \n",
    " * @param a - first number\n",
    " * @param b - second number\n",
    " */\n",
    "function multiply(a: number, b: number): number {\n",
    "    return a * b;\n",
    "  }\n",
    "\n",
    "const llm_with_tools = llm.bindTools([multiply])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3f9dba",
   "metadata": {},
   "source": [
    "If we pass an input - e.g., `\"What is 2 multiplied by 3\"` - we see a tool call returned. \n",
    "\n",
    "The tool call has specific arguments that match the input schema of our function along with the name of the function to call.\n",
    "\n",
    "```\n",
    "{'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9edbe13e-cc72-4685-ac97-2ebb4ceb2544",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "400 Invalid type for 'tools[0]': expected an object, but got null instead.",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "Error: 400 Invalid type for 'tools[0]': expected an object, but got null instead.",
      "    at Function.generate (file:///Users/fabrice/Documents/Dev Local/Tutoriels/langchain-academy/node_modules/openai/error.mjs:41:20)",
      "    at OpenAI.makeStatusError (file:///Users/fabrice/Documents/Dev Local/Tutoriels/langchain-academy/node_modules/openai/core.mjs:286:25)",
      "    at OpenAI.makeRequest (file:///Users/fabrice/Documents/Dev Local/Tutoriels/langchain-academy/node_modules/openai/core.mjs:330:30)",
      "    at eventLoopTick (ext:core/01_core.js:175:7)",
      "    at async file:///Users/fabrice/Documents/Dev Local/Tutoriels/langchain-academy/node_modules/@langchain/openai/dist/chat_models.js:1543:29",
      "    at async RetryOperation._fn (file:///Users/fabrice/Documents/Dev Local/Tutoriels/langchain-academy/node_modules/p-retry/index.js:50:12)"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "const tool_call = await llm_with_tools.invoke([new HumanMessage({content:\"What is 2 multiplied by 3\", name:\"Lance\"})])\n",
    "console.log('tool_call :>> ', tool_call);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a78178cb-fa43-45b5-be5e-5a22bda5a5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'call_OP4qwtGk4gTIaIySPFHkpbB2',\n",
       "  'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'},\n",
       "  'type': 'function'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.additional_kwargs['tool_calls']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c10f9a-2372-486b-9305-55b7c41ecd6e",
   "metadata": {},
   "source": [
    "## Using messages as state\n",
    "\n",
    "With these foundations in place, we can now use [`messages`](https://python.langchain.com/v0.2/docs/concepts/#messages) in our graph state.\n",
    "\n",
    "Let's define our state, `MessagesState`, as a `TypedDict` with a single key: `messages`.\n",
    "\n",
    "`messages` is simply a list of messages, as we defined above (e.g., `HumanMessage`, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3699dd5c-398c-43c7-b496-fd87e55e11ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import {BaseMessage, AIMessage, HumanMessage} from \"@langchain/core/messages\";\n",
    "\n",
    "class MessagesState {\n",
    "    messages: [BaseMessage]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211cba3e-ebba-4b91-a539-1cbc28b4a40e",
   "metadata": {},
   "source": [
    "## Reducers\n",
    "\n",
    "Now, we have a minor problem! \n",
    "\n",
    "As we discussed, each node will return a new value for our state key `messages`.\n",
    "\n",
    "But, this new value will [will override](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) the prior `messages` value.\n",
    " \n",
    "As our graph runs, we want to **append** messages to to our `messages` state key.\n",
    " \n",
    "We can use [reducer functions](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) address this.\n",
    "\n",
    "Reducers allow us to specify how state updates are performed.\n",
    "\n",
    "If no reducer function is specified, then it is assumed that updates to the key should *override it* as we saw before.\n",
    " \n",
    "But, to append messages, we can use the pre-built `add_messages` reducer.\n",
    "\n",
    "This ensures that any messages are appended to the existing list of messages.\n",
    "\n",
    "We annotate simply need to annotate our `messages` key with the `add_messages` reducer function as metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b33eb72-3197-4870-b9a3-0da8056c40c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import type {BaseMessage, } from \"@langchain/core/messages\";\n",
    "import { Annotation, messagesStateReducer, type Messages } from \"@langchain/langgraph\";\n",
    "\n",
    "const MessageState = Annotation.Root({\n",
    "    messages: Annotation<BaseMessage[], Messages>({\n",
    "      reducer: messagesStateReducer,\n",
    "    }),\n",
    "  });"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3663e574-ba15-46be-a37c-48c8052d693b",
   "metadata": {},
   "source": [
    "Since having a list of messages in graph state is so common, LangGraph has a pre-built [`MessagesState`](https://langchain-ai.github.io/langgraph/concepts/low_level/#messagesstate)! \n",
    "\n",
    "`MessagesState` is defined: \n",
    "\n",
    "* With a pre-build single `messages` key\n",
    "* This is a list of `AnyMessage` objects \n",
    "* It uses the `add_messages` reducer\n",
    "\n",
    "We'll usually use `MessagesState` because it is less verbose than defining a custom `TypedDict`, as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ab516ee-eab1-4856-8210-99f1fe499672",
   "metadata": {},
   "outputs": [],
   "source": [
    "//from langgraph.graph import MessagesState\n",
    "\n",
    "//class MessagesState(MessagesState):\n",
    " // Add any keys needed beyond messages, which is pre-built pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b0fff7-60a2-4582-8f12-3a3ab6633d6c",
   "metadata": {},
   "source": [
    "To go a bit deeper, we can see how the `add_messages` reducer works in isolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23ffea76-16a5-4053-a1bc-91e0101d91dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  AIMessage {\n",
       "    \"id\": \"78b71e1d-1339-4e2f-b3fb-b2ed02bdd313\",\n",
       "    \"content\": \"Hello! How can I assist you?\",\n",
       "    \"name\": \"Model\",\n",
       "    \"additional_kwargs\": {},\n",
       "    \"response_metadata\": {},\n",
       "    \"tool_calls\": [],\n",
       "    \"invalid_tool_calls\": []\n",
       "  },\n",
       "  HumanMessage {\n",
       "    \"id\": \"743c993d-cf12-45ac-b4be-ddf30190156d\",\n",
       "    \"content\": \"I'm looking for information on marine biology.\",\n",
       "    \"name\": \"Lance\",\n",
       "    \"additional_kwargs\": {},\n",
       "    \"response_metadata\": {}\n",
       "  },\n",
       "  AIMessage {\n",
       "    \"id\": \"fc996e9a-9b11-4714-8c0f-ce720dee6065\",\n",
       "    \"content\": \"Sure, I can help with that. What specifically are you interested in?\",\n",
       "    \"name\": \"Model\",\n",
       "    \"additional_kwargs\": {},\n",
       "    \"response_metadata\": {},\n",
       "    \"tool_calls\": [],\n",
       "    \"invalid_tool_calls\": []\n",
       "  }\n",
       "]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Initial state\n",
    "const initial_messages = [new AIMessage({content:\"Hello! How can I assist you?\", name:\"Model\"}),\n",
    "                    new HumanMessage({content:\"I'm looking for information on marine biology.\", name:\"Lance\"})\n",
    "                   ]\n",
    "\n",
    "// New message to add\n",
    "const new_message = new AIMessage({content:\"Sure, I can help with that. What specifically are you interested in?\", name:\"Model\"})\n",
    "\n",
    "// Test\n",
    "messagesStateReducer(initial_messages , new_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485adccc-f262-49dd-af4f-a30e9b6a48e2",
   "metadata": {},
   "source": [
    "## Our graph\n",
    "\n",
    "Now, lets use `MessagesState` with a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b5306639-7e6a-44be-8471-8d2631701cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateGraph {\n",
       "  nodes: {\n",
       "    tool_calling_llm: {\n",
       "      runnable: RunnableCallable {\n",
       "        lc_serializable: \u001b[33mfalse\u001b[39m,\n",
       "        lc_kwargs: {},\n",
       "        lc_runnable: \u001b[33mtrue\u001b[39m,\n",
       "        name: \u001b[32m\"tool_calling_llm\"\u001b[39m,\n",
       "        lc_namespace: [ \u001b[32m\"langgraph\"\u001b[39m ],\n",
       "        func: \u001b[36m[Function: tool_calling_llm]\u001b[39m,\n",
       "        tags: \u001b[90mundefined\u001b[39m,\n",
       "        config: \u001b[90mundefined\u001b[39m,\n",
       "        trace: \u001b[33mfalse\u001b[39m,\n",
       "        recurse: \u001b[33mtrue\u001b[39m\n",
       "      },\n",
       "      retryPolicy: \u001b[90mundefined\u001b[39m,\n",
       "      metadata: \u001b[90mundefined\u001b[39m,\n",
       "      input: {\n",
       "        messages: BinaryOperatorAggregate {\n",
       "          ValueType: \u001b[90mundefined\u001b[39m,\n",
       "          UpdateType: \u001b[90mundefined\u001b[39m,\n",
       "          lg_is_channel: \u001b[33mtrue\u001b[39m,\n",
       "          lc_graph_name: \u001b[32m\"BinaryOperatorAggregate\"\u001b[39m,\n",
       "          value: [],\n",
       "          operator: \u001b[36m[Function: messagesStateReducer]\u001b[39m,\n",
       "          initialValueFactory: \u001b[36m[Function: default]\u001b[39m\n",
       "        }\n",
       "      },\n",
       "      subgraphs: \u001b[90mundefined\u001b[39m\n",
       "    }\n",
       "  },\n",
       "  edges: Set(2) {\n",
       "    [ \u001b[32m\"__start__\"\u001b[39m, \u001b[32m\"tool_calling_llm\"\u001b[39m ],\n",
       "    [ \u001b[32m\"tool_calling_llm\"\u001b[39m, \u001b[32m\"__end__\"\u001b[39m ]\n",
       "  },\n",
       "  branches: {},\n",
       "  entryPoint: \u001b[90mundefined\u001b[39m,\n",
       "  compiled: \u001b[33mtrue\u001b[39m,\n",
       "  channels: {\n",
       "    messages: BinaryOperatorAggregate {\n",
       "      ValueType: \u001b[90mundefined\u001b[39m,\n",
       "      UpdateType: \u001b[90mundefined\u001b[39m,\n",
       "      lg_is_channel: \u001b[33mtrue\u001b[39m,\n",
       "      lc_graph_name: \u001b[32m\"BinaryOperatorAggregate\"\u001b[39m,\n",
       "      value: [],\n",
       "      operator: \u001b[36m[Function: messagesStateReducer]\u001b[39m,\n",
       "      initialValueFactory: \u001b[36m[Function: default]\u001b[39m\n",
       "    }\n",
       "  },\n",
       "  waitingEdges: Set(0) {},\n",
       "  _schemaDefinition: {\n",
       "    messages: BinaryOperatorAggregate {\n",
       "      ValueType: \u001b[90mundefined\u001b[39m,\n",
       "      UpdateType: \u001b[90mundefined\u001b[39m,\n",
       "      lg_is_channel: \u001b[33mtrue\u001b[39m,\n",
       "      lc_graph_name: \u001b[32m\"BinaryOperatorAggregate\"\u001b[39m,\n",
       "      value: [],\n",
       "      operator: \u001b[36m[Function: messagesStateReducer]\u001b[39m,\n",
       "      initialValueFactory: \u001b[36m[Function: default]\u001b[39m\n",
       "    }\n",
       "  },\n",
       "  _inputDefinition: {\n",
       "    messages: BinaryOperatorAggregate {\n",
       "      ValueType: \u001b[90mundefined\u001b[39m,\n",
       "      UpdateType: \u001b[90mundefined\u001b[39m,\n",
       "      lg_is_channel: \u001b[33mtrue\u001b[39m,\n",
       "      lc_graph_name: \u001b[32m\"BinaryOperatorAggregate\"\u001b[39m,\n",
       "      value: [],\n",
       "      operator: \u001b[36m[Function: messagesStateReducer]\u001b[39m,\n",
       "      initialValueFactory: \u001b[36m[Function: default]\u001b[39m\n",
       "    }\n",
       "  },\n",
       "  _outputDefinition: {\n",
       "    messages: BinaryOperatorAggregate {\n",
       "      ValueType: \u001b[90mundefined\u001b[39m,\n",
       "      UpdateType: \u001b[90mundefined\u001b[39m,\n",
       "      lg_is_channel: \u001b[33mtrue\u001b[39m,\n",
       "      lc_graph_name: \u001b[32m\"BinaryOperatorAggregate\"\u001b[39m,\n",
       "      value: [],\n",
       "      operator: \u001b[36m[Function: messagesStateReducer]\u001b[39m,\n",
       "      initialValueFactory: \u001b[36m[Function: default]\u001b[39m\n",
       "    }\n",
       "  },\n",
       "  _schemaDefinitions: Map(1) {\n",
       "    {\n",
       "      messages: BinaryOperatorAggregate {\n",
       "        ValueType: \u001b[90mundefined\u001b[39m,\n",
       "        UpdateType: \u001b[90mundefined\u001b[39m,\n",
       "        lg_is_channel: \u001b[33mtrue\u001b[39m,\n",
       "        lc_graph_name: \u001b[32m\"BinaryOperatorAggregate\"\u001b[39m,\n",
       "        value: [],\n",
       "        operator: \u001b[36m[Function: messagesStateReducer]\u001b[39m,\n",
       "        initialValueFactory: \u001b[36m[Function: default]\u001b[39m\n",
       "      }\n",
       "    } => {\n",
       "      messages: BinaryOperatorAggregate {\n",
       "        ValueType: \u001b[90mundefined\u001b[39m,\n",
       "        UpdateType: \u001b[90mundefined\u001b[39m,\n",
       "        lg_is_channel: \u001b[33mtrue\u001b[39m,\n",
       "        lc_graph_name: \u001b[32m\"BinaryOperatorAggregate\"\u001b[39m,\n",
       "        value: [],\n",
       "        operator: \u001b[36m[Function: messagesStateReducer]\u001b[39m,\n",
       "        initialValueFactory: \u001b[36m[Function: default]\u001b[39m\n",
       "      }\n",
       "    }\n",
       "  },\n",
       "  _configSchema: \u001b[90mundefined\u001b[39m\n",
       "}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import {\n",
    "    StateGraph,\n",
    "    START,\n",
    "    END,\n",
    "    Annotation,\n",
    "    MessagesAnnotation\n",
    "  } from \"@langchain/langgraph\";\n",
    "  import {AIMessage, HumanMessage} from \"@langchain/core/messages\";\n",
    "  \n",
    "  export const StateAnnotation = Annotation.Root({\n",
    "    ...MessagesAnnotation.spec,\n",
    "  });\n",
    "\n",
    "// Node\n",
    "const tool_calling_llm = (state: any) => {\n",
    "  return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "}\n",
    "\n",
    "// Build graph\n",
    "const builder = new StateGraph(MessagesAnnotation);\n",
    "builder.addNode(\"tool_calling_llm\", tool_calling_llm)\n",
    ".addEdge(START, \"tool_calling_llm\")\n",
    ".addEdge(\"tool_calling_llm\", END)\n",
    "export const graph = builder.compile()\n",
    "\n",
    "// View\n",
    "// display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8909771-7786-47d6-a53d-6bbc3b365737",
   "metadata": {},
   "source": [
    "If we pass in `Hello!`, the LLM responds without any tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "983e2487-c0a5-40a2-afbc-aa53ff49fefc",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Unable to coerce message from array: only human, AI, system, or tool message coercion is currently supported.\n\nReceived: {}\n\nTroubleshooting URL: https://js.langchain.com/docs/troubleshooting/errors/MESSAGE_COERCION_FAILURE/\n",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "Error: Unable to coerce message from array: only human, AI, system, or tool message coercion is currently supported.",
      "",
      "Received: {}",
      "",
      "Troubleshooting URL: https://js.langchain.com/docs/troubleshooting/errors/MESSAGE_COERCION_FAILURE/",
      "",
      "    at _constructMessageFromParams (file:///Users/fabrice/Documents/Dev Local/Tutoriels/langchain-academy/node_modules/@langchain/core/dist/messages/utils.js:92:47)",
      "    at coerceMessageLikeToMessage (file:///Users/fabrice/Documents/Dev Local/Tutoriels/langchain-academy/node_modules/@langchain/core/dist/messages/utils.js:112:16)",
      "    at Array.map (<anonymous>)",
      "    at BinaryOperatorAggregate.messagesStateReducer [as operator] (file:///Users/fabrice/Documents/Dev Local/Tutoriels/langchain-academy/node_modules/@langchain/langgraph/dist/graph/message.js:14:38)",
      "    at BinaryOperatorAggregate.update (file:///Users/fabrice/Documents/Dev Local/Tutoriels/langchain-academy/node_modules/@langchain/langgraph/dist/channels/binop.js:54:35)",
      "    at _applyWrites (file:///Users/fabrice/Documents/Dev Local/Tutoriels/langchain-academy/node_modules/@langchain/langgraph/dist/pregel/algo.js:169:46)",
      "    at PregelLoop.tick (file:///Users/fabrice/Documents/Dev Local/Tutoriels/langchain-academy/node_modules/@langchain/langgraph/dist/pregel/loop.js:474:44)",
      "    at runLoop (file:///Users/fabrice/Documents/Dev Local/Tutoriels/langchain-academy/node_modules/@langchain/langgraph/dist/pregel/index.js:774:35)"
     ]
    }
   ],
   "source": [
    "const nextState = await graph.invoke({messages: [new HumanMessage(\"Hello\")],})\n",
    "\n",
    "console.log(nextState)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3588688b-efd9-4dbc-abf2-7903e3ef89ba",
   "metadata": {},
   "source": [
    "The LLM chooses to use a tool when it determines that the input or task requires the functionality provided by that tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7fe8b042-ecc8-426f-995e-cc1bbaf7cacc",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Unable to coerce message from array: only human, AI, system, or tool message coercion is currently supported.\n\nReceived: {}\n\nTroubleshooting URL: https://js.langchain.com/docs/troubleshooting/errors/MESSAGE_COERCION_FAILURE/\n",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "Error: Unable to coerce message from array: only human, AI, system, or tool message coercion is currently supported.",
      "",
      "Received: {}",
      "",
      "Troubleshooting URL: https://js.langchain.com/docs/troubleshooting/errors/MESSAGE_COERCION_FAILURE/",
      "",
      "    at _constructMessageFromParams (file:///Users/fabrice/Documents/Dev Local/Tutoriels/langchain-academy/node_modules/@langchain/core/dist/messages/utils.js:92:47)",
      "    at coerceMessageLikeToMessage (file:///Users/fabrice/Documents/Dev Local/Tutoriels/langchain-academy/node_modules/@langchain/core/dist/messages/utils.js:112:16)",
      "    at Array.map (<anonymous>)",
      "    at BinaryOperatorAggregate.messagesStateReducer [as operator] (file:///Users/fabrice/Documents/Dev Local/Tutoriels/langchain-academy/node_modules/@langchain/langgraph/dist/graph/message.js:14:38)",
      "    at BinaryOperatorAggregate.update (file:///Users/fabrice/Documents/Dev Local/Tutoriels/langchain-academy/node_modules/@langchain/langgraph/dist/channels/binop.js:54:35)",
      "    at _applyWrites (file:///Users/fabrice/Documents/Dev Local/Tutoriels/langchain-academy/node_modules/@langchain/langgraph/dist/pregel/algo.js:169:46)",
      "    at PregelLoop.tick (file:///Users/fabrice/Documents/Dev Local/Tutoriels/langchain-academy/node_modules/@langchain/langgraph/dist/pregel/loop.js:474:44)",
      "    at runLoop (file:///Users/fabrice/Documents/Dev Local/Tutoriels/langchain-academy/node_modules/@langchain/langgraph/dist/pregel/index.js:774:35)",
      "    at eventLoopTick (ext:core/01_core.js:175:7)"
     ]
    }
   ],
   "source": [
    "const next = await graph.invoke({\"messages\": [new HumanMessage(\"Multiply 2 and 3\")]})\n",
    "console.log('messages :>> ', next);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311fbae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
